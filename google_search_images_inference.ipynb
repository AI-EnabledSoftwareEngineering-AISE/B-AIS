{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8515a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d6b68b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>caption</th>\n",
       "      <th>context</th>\n",
       "      <th>tag</th>\n",
       "      <th>query_gt</th>\n",
       "      <th>gt_coverage</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309</td>\n",
       "      <td>Police are calling for public assistance after...</td>\n",
       "      <td>Police areseeking public help after a man alle...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:0, train:0, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309</td>\n",
       "      <td>Passengers are waiting to bord train.</td>\n",
       "      <td>The Victorian Minister for Transport Infrastru...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>Box Hill’s $754,000 footbridge across the tracks</td>\n",
       "      <td>This is the story of the $56.5 million grade s...</td>\n",
       "      <td>[pedestrian:0, close:0, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>309</td>\n",
       "      <td>Metro Trains have so far been unable to say wh...</td>\n",
       "      <td>Metro Trains have so far been unable to say wh...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:0, train:0, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>The Electric Tilt Train, the fastest train in ...</td>\n",
       "      <td>High-speed rail in Australia has been under in...</td>\n",
       "      <td>[pedestrian:1, close:1, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>99</td>\n",
       "      <td>ARCE Students Place Second in EERI Seismic Des...</td>\n",
       "      <td>A team of Cal Poly architectural engineering (...</td>\n",
       "      <td>[pedestrian:0, structure:1, concrete:0, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>99</td>\n",
       "      <td>Timber Strong Provides Real-World Engineering ...</td>\n",
       "      <td>For the last three years, Simpson Strong-Tie h...</td>\n",
       "      <td>[pedestrian:1, structure:0, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>99</td>\n",
       "      <td>Students Compete to Design, Build Timber Struc...</td>\n",
       "      <td>Hammer strikes echoed through the sunny plaza ...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>99</td>\n",
       "      <td>Cal Poly Architectural Engineering Students Wi...</td>\n",
       "      <td>SAN LUIS OBISPO – Six Cal Poly architectural e...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>99</td>\n",
       "      <td>Teams assemble their structures at the Disneyl...</td>\n",
       "      <td>APA – The Engineered Wood Association, the Ame...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                            caption  \\\n",
       "0     309  Police are calling for public assistance after...   \n",
       "1     309              Passengers are waiting to bord train.   \n",
       "2     309   Box Hill’s $754,000 footbridge across the tracks   \n",
       "3     309  Metro Trains have so far been unable to say wh...   \n",
       "4     309  The Electric Tilt Train, the fastest train in ...   \n",
       "..    ...                                                ...   \n",
       "306    99  ARCE Students Place Second in EERI Seismic Des...   \n",
       "307    99  Timber Strong Provides Real-World Engineering ...   \n",
       "308    99  Students Compete to Design, Build Timber Struc...   \n",
       "309    99  Cal Poly Architectural Engineering Students Wi...   \n",
       "310    99  Teams assemble their structures at the Disneyl...   \n",
       "\n",
       "                                               context  \\\n",
       "0    Police areseeking public help after a man alle...   \n",
       "1    The Victorian Minister for Transport Infrastru...   \n",
       "2    This is the story of the $56.5 million grade s...   \n",
       "3    Metro Trains have so far been unable to say wh...   \n",
       "4    High-speed rail in Australia has been under in...   \n",
       "..                                                 ...   \n",
       "306  A team of Cal Poly architectural engineering (...   \n",
       "307  For the last three years, Simpson Strong-Tie h...   \n",
       "308  Hammer strikes echoed through the sunny plaza ...   \n",
       "309  SAN LUIS OBISPO – Six Cal Poly architectural e...   \n",
       "310  APA – The Engineered Wood Association, the Ame...   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    [pedestrian:1, close:0, rail:0, train:0, railw...   \n",
       "1    [pedestrian:1, close:0, rail:1, train:1, railw...   \n",
       "2    [pedestrian:0, close:0, rail:1, train:1, railw...   \n",
       "3    [pedestrian:1, close:0, rail:0, train:0, railw...   \n",
       "4    [pedestrian:1, close:1, rail:1, train:1, railw...   \n",
       "..                                                 ...   \n",
       "306  [pedestrian:0, structure:1, concrete:0, masonr...   \n",
       "307  [pedestrian:1, structure:0, concrete:1, masonr...   \n",
       "308  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "309  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "310  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "\n",
       "                                              query_gt  gt_coverage  \\\n",
       "0      [pedestrian, close, rail, train, railway, line]     0.333333   \n",
       "1      [pedestrian, close, rail, train, railway, line]     0.833333   \n",
       "2      [pedestrian, close, rail, train, railway, line]     0.500000   \n",
       "3      [pedestrian, close, rail, train, railway, line]     0.333333   \n",
       "4      [pedestrian, close, rail, train, railway, line]     0.833333   \n",
       "..                                                 ...          ...   \n",
       "306  [pedestrian, structure, concrete, masonry, ins...     0.333333   \n",
       "307  [pedestrian, structure, concrete, masonry, ins...     0.222222   \n",
       "308  [pedestrian, structure, concrete, masonry, ins...     0.666667   \n",
       "309  [pedestrian, structure, concrete, masonry, ins...     0.888889   \n",
       "310  [pedestrian, structure, concrete, masonry, ins...     0.888889   \n",
       "\n",
       "                                                 image  \n",
       "0    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "1    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "2    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "3    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "4    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "..                                                 ...  \n",
       "306  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "307  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "308  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "309  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "310  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_path = '/raid/AISSEL/Hamed/datasets'\n",
    "df = pd.read_pickle(f'{d_path}/google_images.pk')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7399a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/barzamini/ofa/OFA\n"
     ]
    }
   ],
   "source": [
    "%cd OFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403f1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fairseq import utils,tasks\n",
    "from fairseq import checkpoint_utils\n",
    "from utils.eval_utils import eval_step\n",
    "from tasks.mm_tasks.caption import CaptionTask\n",
    "from models.ofa import OFAModel\n",
    "from PIL import Image\n",
    "\n",
    "# Register caption task\n",
    "tasks.register_task('caption',CaptionTask)\n",
    "\n",
    "# turn on cuda if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use fp16 only when GPU is available\n",
    "use_fp16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce3f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 18:12:55 | INFO | tasks.ofa_task | source dictionary: 59457 types\n",
      "2022-05-06 18:12:55 | INFO | tasks.ofa_task | target dictionary: 59457 types\n",
      "/home/barzamini/.conda/envs/ofa/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755861072/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ckpt & config\n",
    "#large model\n",
    "# cp_path = f'checkpoints/caption.pt'\n",
    "#base model\n",
    "# cp_path = 'checkpoints/caption_base_best.pt'\n",
    "\n",
    "#base retrained model by missinig topics\n",
    "cp_path = 'checkpoints/caption_stage2_best_base.pt'\n",
    "\n",
    "overrides={\"bpe_dir\":\"utils/BPE\", \"eval_cider\":False, \"beam\":5, \"max_len_b\":16, \"no_repeat_ngram_size\":3, \"seed\":7}\n",
    "models, cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
    "        utils.split_paths(cp_path),\n",
    "        arg_overrides=overrides\n",
    "    )\n",
    "\n",
    "# Move models to GPU\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    if use_fp16:\n",
    "        model.half()\n",
    "    if use_cuda and not cfg.distributed_training.pipeline_model_parallel:\n",
    "        model.cuda()\n",
    "    model.prepare_for_inference_(cfg)\n",
    "\n",
    "# Initialize generator\n",
    "generator = task.build_generator(models, cfg.generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd40096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barzamini/.conda/envs/ofa/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  \n",
      "/home/barzamini/.conda/envs/ofa/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "# Image transform\n",
    "from torchvision import transforms\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "patch_resize_transform = transforms.Compose([\n",
    "    lambda image: image.convert(\"RGB\"),\n",
    "    transforms.Resize((cfg.task.patch_image_size, cfg.task.patch_image_size), interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# Text preprocess\n",
    "bos_item = torch.LongTensor([task.src_dict.bos()])\n",
    "eos_item = torch.LongTensor([task.src_dict.eos()])\n",
    "pad_idx = task.src_dict.pad()\n",
    "def encode_text(text, length=None, append_bos=False, append_eos=False):\n",
    "    s = task.tgt_dict.encode_line(\n",
    "        line=task.bpe.encode(text),\n",
    "        add_if_not_exist=False,\n",
    "        append_eos=False\n",
    "    ).long()\n",
    "    if length is not None:\n",
    "        s = s[:length]\n",
    "    if append_bos:\n",
    "        s = torch.cat([bos_item, s])\n",
    "    if append_eos:\n",
    "        s = torch.cat([s, eos_item])\n",
    "    return s\n",
    "\n",
    "# Construct input for caption task\n",
    "def construct_sample(image: Image):\n",
    "    patch_image = patch_resize_transform(image).unsqueeze(0)\n",
    "    patch_mask = torch.tensor([True])\n",
    "    src_text = encode_text(\" what does the image describe?\", append_bos=True, append_eos=True).unsqueeze(0)\n",
    "    src_length = torch.LongTensor([s.ne(pad_idx).long().sum() for s in src_text])\n",
    "    sample = {\n",
    "        \"id\":np.array(['42']),\n",
    "        \"net_input\": {\n",
    "            \"src_tokens\": src_text,\n",
    "            \"src_lengths\": src_length,\n",
    "            \"patch_images\": patch_image,\n",
    "            \"patch_masks\": patch_mask\n",
    "        }\n",
    "    }\n",
    "    return sample\n",
    "  \n",
    "# Function to turn FP32 to FP16\n",
    "def apply_half(t):\n",
    "    if t.dtype is torch.float32:\n",
    "        return t.to(dtype=torch.half)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acd8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(b64_img):\n",
    "    image_64_decode = base64.b64decode(b64_img) \n",
    "    image_result = open('test.jpg', 'wb')\n",
    "    image_result.write(image_64_decode)\n",
    "    image = Image.open('test.jpg')\n",
    "\n",
    "    # Construct input sample & preprocess for GPU if cuda available\n",
    "    sample = construct_sample(image)\n",
    "    sample = utils.move_to_cuda(sample) if use_cuda else sample\n",
    "    sample = utils.apply_to_sample(apply_half, sample) if use_fp16 else sample\n",
    "    with torch.no_grad():\n",
    "        result, scores = eval_step(task, generator, models, sample)\n",
    "#     print(f'\\n {result}\\n')\n",
    "    return result[0]['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e35dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barzamini/.conda/envs/ofa/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beams_buf = indices_buf // vocab_size\n",
      "/home/barzamini/ofa/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  unfin_idx = bbsz_idx // beam_size\n"
     ]
    }
   ],
   "source": [
    "df['ofa_caption'] = df['image'].apply(get_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95133bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>caption</th>\n",
       "      <th>context</th>\n",
       "      <th>tag</th>\n",
       "      <th>query_gt</th>\n",
       "      <th>gt_coverage</th>\n",
       "      <th>image</th>\n",
       "      <th>ofa_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309</td>\n",
       "      <td>Police are calling for public assistance after...</td>\n",
       "      <td>Police areseeking public help after a man alle...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:0, train:0, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>people wearing face masks walk outside a train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309</td>\n",
       "      <td>Passengers are waiting to bord train.</td>\n",
       "      <td>The Victorian Minister for Transport Infrastru...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>a crowd of people waiting for the train to arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>Box Hill’s $754,000 footbridge across the tracks</td>\n",
       "      <td>This is the story of the $56.5 million grade s...</td>\n",
       "      <td>[pedestrian:0, close:0, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>a train passes under the pedestrian bridge ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>309</td>\n",
       "      <td>Metro Trains have so far been unable to say wh...</td>\n",
       "      <td>Metro Trains have so far been unable to say wh...</td>\n",
       "      <td>[pedestrian:1, close:0, rail:0, train:0, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>a train arrives at a station in the city of vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>The Electric Tilt Train, the fastest train in ...</td>\n",
       "      <td>High-speed rail in Australia has been under in...</td>\n",
       "      <td>[pedestrian:1, close:1, rail:1, train:1, railw...</td>\n",
       "      <td>[pedestrian, close, rail, train, railway, line]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>A yellow train on the tracks at the station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>99</td>\n",
       "      <td>ARCE Students Place Second in EERI Seismic Des...</td>\n",
       "      <td>A team of Cal Poly architectural engineering (...</td>\n",
       "      <td>[pedestrian:0, structure:1, concrete:0, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>people working on the construction of a wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>99</td>\n",
       "      <td>Timber Strong Provides Real-World Engineering ...</td>\n",
       "      <td>For the last three years, Simpson Strong-Tie h...</td>\n",
       "      <td>[pedestrian:1, structure:0, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>A group of people posing for a picture in fron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>99</td>\n",
       "      <td>Students Compete to Design, Build Timber Struc...</td>\n",
       "      <td>Hammer strikes echoed through the sunny plaza ...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>pedestrians walking on the sidewalk in front o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>99</td>\n",
       "      <td>Cal Poly Architectural Engineering Students Wi...</td>\n",
       "      <td>SAN LUIS OBISPO – Six Cal Poly architectural e...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>A group of people standing on top of a box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>99</td>\n",
       "      <td>Teams assemble their structures at the Disneyl...</td>\n",
       "      <td>APA – The Engineered Wood Association, the Ame...</td>\n",
       "      <td>[pedestrian:1, structure:1, concrete:1, masonr...</td>\n",
       "      <td>[pedestrian, structure, concrete, masonry, ins...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>A construction workers are working on the roof...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                            caption  \\\n",
       "0     309  Police are calling for public assistance after...   \n",
       "1     309              Passengers are waiting to bord train.   \n",
       "2     309   Box Hill’s $754,000 footbridge across the tracks   \n",
       "3     309  Metro Trains have so far been unable to say wh...   \n",
       "4     309  The Electric Tilt Train, the fastest train in ...   \n",
       "..    ...                                                ...   \n",
       "306    99  ARCE Students Place Second in EERI Seismic Des...   \n",
       "307    99  Timber Strong Provides Real-World Engineering ...   \n",
       "308    99  Students Compete to Design, Build Timber Struc...   \n",
       "309    99  Cal Poly Architectural Engineering Students Wi...   \n",
       "310    99  Teams assemble their structures at the Disneyl...   \n",
       "\n",
       "                                               context  \\\n",
       "0    Police areseeking public help after a man alle...   \n",
       "1    The Victorian Minister for Transport Infrastru...   \n",
       "2    This is the story of the $56.5 million grade s...   \n",
       "3    Metro Trains have so far been unable to say wh...   \n",
       "4    High-speed rail in Australia has been under in...   \n",
       "..                                                 ...   \n",
       "306  A team of Cal Poly architectural engineering (...   \n",
       "307  For the last three years, Simpson Strong-Tie h...   \n",
       "308  Hammer strikes echoed through the sunny plaza ...   \n",
       "309  SAN LUIS OBISPO – Six Cal Poly architectural e...   \n",
       "310  APA – The Engineered Wood Association, the Ame...   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    [pedestrian:1, close:0, rail:0, train:0, railw...   \n",
       "1    [pedestrian:1, close:0, rail:1, train:1, railw...   \n",
       "2    [pedestrian:0, close:0, rail:1, train:1, railw...   \n",
       "3    [pedestrian:1, close:0, rail:0, train:0, railw...   \n",
       "4    [pedestrian:1, close:1, rail:1, train:1, railw...   \n",
       "..                                                 ...   \n",
       "306  [pedestrian:0, structure:1, concrete:0, masonr...   \n",
       "307  [pedestrian:1, structure:0, concrete:1, masonr...   \n",
       "308  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "309  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "310  [pedestrian:1, structure:1, concrete:1, masonr...   \n",
       "\n",
       "                                              query_gt  gt_coverage  \\\n",
       "0      [pedestrian, close, rail, train, railway, line]     0.333333   \n",
       "1      [pedestrian, close, rail, train, railway, line]     0.833333   \n",
       "2      [pedestrian, close, rail, train, railway, line]     0.500000   \n",
       "3      [pedestrian, close, rail, train, railway, line]     0.333333   \n",
       "4      [pedestrian, close, rail, train, railway, line]     0.833333   \n",
       "..                                                 ...          ...   \n",
       "306  [pedestrian, structure, concrete, masonry, ins...     0.333333   \n",
       "307  [pedestrian, structure, concrete, masonry, ins...     0.222222   \n",
       "308  [pedestrian, structure, concrete, masonry, ins...     0.666667   \n",
       "309  [pedestrian, structure, concrete, masonry, ins...     0.888889   \n",
       "310  [pedestrian, structure, concrete, masonry, ins...     0.888889   \n",
       "\n",
       "                                                 image  \\\n",
       "0    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "1    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "2    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "3    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "4    /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "..                                                 ...   \n",
       "306  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "307  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "308  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "309  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "310  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "\n",
       "                                           ofa_caption  \n",
       "0    people wearing face masks walk outside a train...  \n",
       "1    a crowd of people waiting for the train to arr...  \n",
       "2    a train passes under the pedestrian bridge ove...  \n",
       "3    a train arrives at a station in the city of vi...  \n",
       "4          A yellow train on the tracks at the station  \n",
       "..                                                 ...  \n",
       "306       people working on the construction of a wall  \n",
       "307  A group of people posing for a picture in fron...  \n",
       "308  pedestrians walking on the sidewalk in front o...  \n",
       "309         A group of people standing on top of a box  \n",
       "310  A construction workers are working on the roof...  \n",
       "\n",
       "[311 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ee0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = '/raid/AISSEL/Hamed/datasets'\n",
    "# df.to_pickle(f'{d_path}/google_images_with_prediction.pk')\n",
    "# df.to_pickle(f'{d_path}/google_images_with_prediction_base.pk')\n",
    "df.to_pickle(f'{d_path}/google_images_with_prediction_base_missed.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf6d662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\tevaluate.py  __pycache__\t\ttasks\r\n",
      "checkpoints.md\texamples     README_EncouragingLoss.md\ttest.jpg\r\n",
      "colab.md\tfairseq      README.md\t\t\ttrainer.py\r\n",
      "criterions\tLICENSE      requirements.txt\t\ttrain.py\r\n",
      "data\t\tmodels\t     run_scripts\t\ttransformers.md\r\n",
      "datasets.md\tofa_module   spaces.md\t\t\tutils\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a9b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
